{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'Session 2: Spring 2026'\n",
        "subtitle: Big Data Algorithms\n",
        "format:\n",
        "  revealjs:\n",
        "    theme: serif\n",
        "    slide-number: true\n",
        "    chalkboard: true\n",
        "    transition: fade\n",
        "  html:\n",
        "    toc: true\n",
        "  pdf:\n",
        "    documentclass: beamer\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Review from the last session\n",
        "\n",
        "- Universal hash family of functions\n",
        "- Jaccard similarity and distance\n",
        "- Connection between minhash signatures and Jaccard distance\n",
        "\n",
        "## Python Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "rng = np.random.default_rng()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Universal Hash Family\n",
        "\n",
        "A family with the following property:\n",
        "\n",
        "> for any pair of keys in the universe of keys (i.e. $U$), a hash\n",
        "> function drawn uniformly at random from the family will cause the keys\n",
        "> to collide with an expected probability of $1/m$, where $m$ is the\n",
        "> table size.\n",
        "\n",
        "Let $p$ be a large prime, and let $a, b$ be random integers chosen\n",
        "uniformly such that $1 \\leq a \\leq p-1$ and $0 \\leq b \\leq p-1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "rng = np.random.default_rng()\n",
        "class UHF:\n",
        "    \"\"\"A factory for producing a universal family of hash functions\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def is_prime(k):\n",
        "        if k%2==0:\n",
        "            return False\n",
        "        for i in range(3, int(math.sqrt(k)), 2):\n",
        "            if k%i == 0:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def __init__(self, n):\n",
        "        \"\"\"Universe size is n\"\"\"\n",
        "        self.n = n\n",
        "        if n%2==0:\n",
        "            m = n+1\n",
        "        else:\n",
        "            m = n+2\n",
        "        while not(UHF.is_prime(m)):\n",
        "            m = m+2\n",
        "        self.p = m\n",
        "\n",
        "    def make_hash(self, m):\n",
        "        \"\"\"Return a random hash function\n",
        "\n",
        "        m: table size\n",
        "        \"\"\"\n",
        "        a = random.randint(1,self.p-1)\n",
        "        b = random.randint(0,self.p-1)\n",
        "        return lambda k: ((a*k+b)%self.p)%m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test the Universal Hash Family (Exercise)\n",
        "\n",
        "Set up and evaluate an experiment to verify that the family defined\n",
        "above is indeed a universal family. Use a reasonable universe of keys,\n",
        "say integers in $range(1000000)$ and a hash table of size $5000$.\n",
        "\n",
        "- Fix two keys at random\n",
        "- Generate a lot of hash functions and see how many of them collide\n",
        "\n",
        "## Data as Feature Matrices\n",
        "\n",
        "- Each data item is generically referred to as a **document**\n",
        "\n",
        "- In the simplest case, documents are *characterized* by the presence or\n",
        "  absence of *binary* features (indicated by 0 and 1), i.e., the data is\n",
        "  the **characteristic matrix** of the features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "characters = pd.DataFrame({'Hermione': [1,0,0,1,1,0,1],\n",
        "                           'Harry': [0,0,1,1,1,0,1],\n",
        "                           'Ron': [1,1,0,0,0,1,1],\n",
        "                           'Severus': [1,0,0,0,0,1,1]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Jaccard Similarity\n",
        "\n",
        "Jaccard *similarity* between two documents $D_i$ and $D_j$ equals\n",
        "$ \\text{SIM}(i,j) = \\frac{|D_i \\cap D_j|}{|D_i \\cup D_j|}$\n",
        "\n",
        "**Question:** What is the Jaccard similarity between `Harry` and\n",
        "`Hermione`? Between `Severus` and `Ron`?\n",
        "\n",
        "## Compressing a document\\'s representation: Minhash Signatures\n",
        "\n",
        "Choose a *random* permutation $p$ of the features. A **minhash signature**\n",
        "$\\text{sign}_p(i)$ for document $D_i$ using permutation $p$\n",
        "is obtained as follows:\n",
        "\n",
        "- recall that the document is a feature vector in the original order of\n",
        "  features\n",
        "- **Reorder** the feature vector according to the permutation $p$\n",
        "- Among all features present in the document, determine the one with the\n",
        "  **smallest index in the new ordering**! This index is the signature\n",
        "  for the document.\n",
        "\n",
        "## Example (contd)\n",
        "\n",
        "For our example above, consider document `Hermione` with feature vector\n",
        "$[1,0,0,1,1,0,1]$ (the first column above).\n",
        "\n",
        "Consider the *permutation* of the **feature indices** given by\n",
        "$[3,1,0,6,2,5,4]$\n",
        "\n",
        "This says that feature 3 will be numbered 0, feature 1 still numbered 1,\n",
        "feature 0 numbered 2 and so on. Hence, the permutation will **reorder**\n",
        "document `Hermione` as $[\\underline{1},0,1,1,0,0,1]$ e.g. the\n",
        "underlined 1 at the new index **0**, corresponds to the original feature\n",
        "number 3.\n",
        "\n",
        "If we apply the permutation across all characters (columns), we get:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "perm = [3,1,0,6,2,5,4]\n",
        "f_matrix = characters.to_numpy()\n",
        "print(f_matrix)\n",
        "perm_mat = np.take(f_matrix, perm, axis=0)\n",
        "perm_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Computing a signature\n",
        "\n",
        "To determine the **signature** of document `Hermione` according to\n",
        "permutation `perm` above, we just walk down the *permuted* column until\n",
        "we find the **first row index** corresponding to a feature that\n",
        "`Hermione` *contains*, viz. the 1 entry at index **0**.\n",
        "\n",
        "Doing this for all columns, the signatures for the documents (in order)\n",
        "according to `perm` are: 0, 0, 1, 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.argmin(1 - perm_mat, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise\n",
        "\n",
        "- What are the signatures for the other documents according to the\n",
        "  permutation \\[6,4,2,0,5,3,1\\]?\n",
        "\n",
        "- What signatures are possible, in theory, for `Harry`?\n",
        "\n",
        "- What **common signatures** are possible for `Harry` and `Severus`?\n",
        "\n",
        "## Using numpy to compute document signatures\n",
        "\n",
        "We can do this in a variety of ways. For example:\n",
        "\n",
        "- Start with a random permutation $p$ of the row indices. Apply the\n",
        "permutation $p$ to the matrix, then determine the signature by using\n",
        "    `argmin` over the matrix with entries *flipped*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "p_mat = rng.permutation(f_matrix, axis=0)\n",
        "np.argmin(1 - p_mat, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative\n",
        "\n",
        "- We need not actually permute the rows of the matrix at all -\n",
        "    permuting rows can be very expensive with large data. Instead, we\n",
        "    imagine that the rows are numbered from 1 through $m$, the number of\n",
        "    features. A permutation can be thought of as supplying **weights**\n",
        "    for the corresponding features. We multiply each feature by its\n",
        "    weight, then find the smallest non-zero weighted entry in a column:\n",
        "    that is the signature!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## Mask all 0 values\n",
        "n_rows = f_matrix.shape[0]\n",
        "masked = np.where(f_matrix == 0, n_rows+1, f_matrix)\n",
        "perm_arr = np.array(perm) + 1  # make elements non-zero\n",
        "permuted_tr = masked.T * perm_arr  # transpose to do elementwise multiplication\n",
        "signs = np.min(permuted_tr.T, axis=0)\n",
        "print(signs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discussion\n",
        "\n",
        "We used the same permutation `perm` = \\[3,1,0,6,2,5,4\\] but seem to get\n",
        "different signatures. Why is that? Discuss in your group why this is\n",
        "happening. Understand the code below to frame the\n",
        "discussion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "perm_inv = np.argsort(perm)\n",
        "print(perm_inv)\n",
        "np.argmin(1 - np.take(f_matrix, perm, axis=0), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Relationship between Jaccard similarity and signatures\n",
        "\n",
        "Given a *random* permutation $p$, the Jaccard similarity,\n",
        "$\\text{SIM}(i,j)$ is related to signatures by the following property:\n",
        "\n",
        "> $\\text{SIM}(i,j) = \\text{Pr}\\{{\\text{sign}}_p(i) = {\\text{sign}}_p(j)\\} $\n",
        "\n",
        "Thus, the likelihood of two documents being deemed similar (via their\n",
        "signatures) will be in accordance with their (mathematical) similarity!\n",
        "\n",
        "**Proof:** In class!\n",
        "\n",
        "## Minhashing\n",
        "\n",
        "Based on the proof, we can see that if we were to calculate a large\n",
        "number of **different signatures** (each corresponding to a different\n",
        "permutation), we can approximate the true Jaccard similarity of two\n",
        "documents as the fraction of permutations with matching signatures.\n",
        "\n",
        "Random permutations are very expensive to compute: it takes time linear in $n$ to obtain such a permutation. When $n$ is very large, this is\n",
        "infeasible.\n",
        "\n",
        "So, we **approximate the signature** by using a **random hash function**\n",
        "in place of a random permutation!\n",
        "\n",
        "Use the **range** of a hash function applied to the feature indices as\n",
        "a **proxy** for permuting the indices of the features.\n",
        "\n",
        "## Minhash Signatures\n",
        "\n",
        "Minhashing using just one small signature will unfortunately produce\n",
        "both **false positives** and **false negatives** for similarity. We try\n",
        "to mitigate this as follows:\n",
        "\n",
        "- generate **many** small signatures using different hash functions\n",
        "\n",
        "*Minhash similarity* between two documents is the expected proportion of\n",
        "hash functions for which their small signatures agree!\n",
        "\n",
        "## Jaccard Distance\n",
        "\n",
        "The Jaccard distance between two documents $i$ and $j$ is given by\n",
        "$d(i,j)=1 - \\text{SIM}(i,j)$.\n",
        "\n",
        "It is distance *metric*:\n",
        "\n",
        "- it equals 0 iff $D_i = D_j$\n",
        "- it is symmetric: $d(i,j)=d(j,i)$\n",
        "- it satisfies the *triangle inequality*:\n",
        "  $d(i,j) ~<=~ d(i,k) ~+~ d(k,j)$\n",
        "\n",
        "## Exercise\n",
        "\n",
        "- Compute signature matrices for a document using both random\n",
        "  permutations and hash functions\n",
        "\n",
        "- Use the matrices to see how accurately they approximate the true\n",
        "  Jaccard similarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def sign(mat, h_fn, p):\n",
        "    \"\"\"\n",
        "    Return array of signatures for all documents\n",
        "\n",
        "    The shape of the matrix is (m, n) where m = number of documents\n",
        "    and n = number of features. The hash function has domain equal to\n",
        "    the column indices 0, 1, ..., n-1\n",
        "\n",
        "    mat (np.array): 0/1 matrix\n",
        "    h_fn (int -> int): universal hash function whose range is 0, ..., p-1\n",
        "    p (int): upper bound on values returned by hfn\n",
        "    \"\"\"\n",
        "    n_features = mat.shape[1]\n",
        "    masked = np.where(mat == 0, n_features + 1, mat)\n",
        "    s = masked*np.vectorize(h_fn)(np.arange(n_features))\n",
        "    return np.min(s, 1)\n",
        "\n",
        "tbl_size = 53\n",
        "uhf = UHF(tbl_size)\n",
        "h = uhf.make_hash(tbl_size)\n",
        "\n",
        "signatures = sign(f_matrix.T, h, tbl_size)\n",
        "signatures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Locality Sensitive Hashing\n",
        "\n",
        "Basic Ingredients:\n",
        "\n",
        "- A *family* $\\cal{F}$ of \"hash functions\" that produce *short signatures* for items. Ideally, we should have a **diversity** of functions.\n",
        "\n",
        "- A **distance** measure, $d$\n",
        "\n",
        "Then \\[\\cal{F}\\] is a\n",
        "\n",
        "$(d_1, d_2, p_1, p_2)\\text{-sensitive family}$\n",
        "\n",
        "with \\[p_1 > p_2\\] and \\[d_1 < d_2\\], iff for\n",
        "any function \\[h\\] in the family and any pair of items $x$ and $y$:\n",
        "\n",
        "> if $d(x, y) \\leq d_1$, then $~\\text{Pr}\\{h(x) = h(y)\\} \\geq p_1$\n",
        "\n",
        "and\n",
        "\n",
        "> if $d(x, y) \\geq d_2$, then $~\\text{Pr}\\{h(x) = h(y)\\} \\leq p_2$\n",
        "\n",
        "## Implications\n",
        "\n",
        "Thus, the probability of **distant** items getting the same signature is reasonably small, and the probability of items in the same *locality* getting the same signature is reasonably large.\n",
        "\n",
        "> **False positive match probability** bounded above by $p_2$ and\n",
        "> **False negative match probability** bounded above by $1 - p_1$.\n",
        "\n",
        "A Minhash family with Jaccard distance is a $(d_1, d_2, (1-d_1), (1-d_2))$-sensitive family!\n",
        "\n",
        "## Amplification: AND, OR constructions\n",
        "\n",
        "Suppose that $s$ is the probability that two documents have the same signatures.\n",
        "\n",
        "**AND Construction:** Consider $r$ different signatures, and we require **all** to match!\n",
        "\n",
        "> Pairing Probability: $s^r$\n",
        "\n",
        "**OR Construction:** Consider $r$ different signatures, and we require **at least one** to match!\n",
        "\n",
        "> Pairing Probability: $1 - (1-s)^r$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "\n",
        "def set_ax_properties(axis):\n",
        "    axis.set_xlabel('Similarity')\n",
        "    axis.set_ylabel('Pairing Probability')\n",
        "    axis.spines['top'].set_visible(False)\n",
        "    axis.spines['right'].set_visible(False)\n",
        "    axis.yaxis.set_ticks_position('none')\n",
        "    axis.yaxis.tick_left()\n",
        "    axis.xaxis.set_ticks_position('none')\n",
        "    axis.xaxis.tick_bottom()\n",
        "\n",
        "def set_plt_properties(a_plot, title):\n",
        "    a_plot.title(title)\n",
        "    a_plot.legend(loc='best')\n",
        "    a_plot.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AND Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s = np.arange(0.0,1.01,0.01)\n",
        "ax = plt.gca()\n",
        "set_ax_properties(ax)\n",
        "plt.plot(s, s, label='1 row', color='r')\n",
        "plt.plot(s, s**2, label='2 rows', color='g')\n",
        "plt.plot(s, s**3, label='3 rows', color='b')\n",
        "set_plt_properties(plt, \"AND-construction curves\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OR Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s = np.arange(0.0,1.01,0.01)\n",
        "ax = plt.gca()\n",
        "set_ax_properties(ax)\n",
        "plt.plot(s, 1 - (1-s), label='1 row', color='r')\n",
        "plt.plot(s, 1 - (1-s)**2, label='2 rows', color='g')\n",
        "plt.plot(s, 1 - (1-s)**3, label='3 rows', color='b')\n",
        "set_plt_properties(plt, \"OR-construction curves\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Side by Side ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s = np.arange(0.0,1.01,0.01)\n",
        "fig, axes = plt.subplots(1,2, sharey=True)\n",
        "set_ax_properties(axes[0])\n",
        "set_ax_properties(axes[1])\n",
        "axes[0].plot(s, 1 - (1-s), label='1 row', color='r')\n",
        "axes[0].plot(s, 1 - (1-s)**2, label='2 rows', color='g')\n",
        "axes[0].plot(s, 1 - (1-s)**3, label='3 rows', color='b')\n",
        "axes[0].set_title(\"OR-Construction\")\n",
        "axes[1].plot(s, s, label='1 row', color='r')\n",
        "axes[1].plot(s, s**2, label='2 rows', color='g')\n",
        "axes[1].plot(s, s**3, label='3 rows', color='b')\n",
        "axes[1].set_title(\"AND-Construction\")\n",
        "handles, labels = axes[0].get_legend_handles_labels()\n",
        "fig.legend(handles, labels, loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AND-OR Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s = np.arange(0.0,1.01,0.01)\n",
        "ax = plt.gca()\n",
        "set_ax_properties(ax)\n",
        "plt.plot(s, s, '-.', color='k')\n",
        "plt.plot(s, 1 - (1-s)**2, label='2 bands with 1 rows', color='r')\n",
        "plt.plot(s, 1 - (1-s**2)**2, label='2 bands with 2 rows', color='g')\n",
        "plt.plot(s, 1-(1-s**3)**2, label='2 bands with 3 rows', color='b')\n",
        "plt.plot(s, 1-(1-s**4)**2, label='2 bands with 4 rows', color='y')\n",
        "set_plt_properties(plt, \"AND-OR Construction\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OR-AND Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "s = np.arange(0.0,1.01,0.01)\n",
        "ax = plt.gca()\n",
        "plt.plot(s, s, '-.', color='k')\n",
        "plt.plot(s, (1 - (1-s))**2, label='2 bands with 1 rows', color='r')\n",
        "plt.plot(s, (1 - (1-s)**2)**2, label='2 bands with 2 rows', color='g')\n",
        "plt.plot(s, (1-(1-s)**3)**2, label='2 bands with 3 rows', color='b')\n",
        "plt.plot(s, (1-(1-s)**4)**2, label='2 bands with 4 rows', color='y')\n",
        "set_plt_properties(plt, \"OR-AND Construction\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n = 60\n",
        "rows = [3,4,5,6,10]\n",
        "bands = [60//r for r in rows]\n",
        "colors = 'bgrcm'\n",
        "s = np.arange(0.0,1.01,0.01)\n",
        "\n",
        "def and_or_threshold(r, b):\n",
        "    \"\"\"Returns the value of s when the S-curve has probability 0.5\n",
        "\n",
        "    Args:\n",
        "        r (int): number of rows\n",
        "        b (int): number of bands\n",
        "    \"\"\"\n",
        "    return (np.log(2)/b)**(1.0/r)\n",
        "\n",
        "def or_and_threshold(r, b):\n",
        "    \"\"\"Returns the value of s when the S-curve has probability 0.5\n",
        "\n",
        "    Args:\n",
        "        r (int): number of rows\n",
        "        b (int): number of bands\n",
        "    \"\"\"\n",
        "    return 1 - and_or_threshold(r, b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## S-Curves: AND-OR construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "params = zip(rows,bands,colors)\n",
        "ax = plt.gca()\n",
        "plt.title(\"AND-OR S-curves: 60 signatures\")\n",
        "z = 0.2\n",
        "for r,b,c in params:\n",
        "    plt.plot(s, 1-(1-s**r)**b, label='%d rows'%(r,),\n",
        "             color=c)\n",
        "    t = and_or_threshold(r,b)\n",
        "    pair_prob = 1-(1-t**r)**b\n",
        "    plt.plot([t,t],[0,pair_prob],'o--',color=c)\n",
        "    ax.annotate('%3.2f'%t, xy=(t,pair_prob),\n",
        "                xytext=(t+0.1,pair_prob+z),color=c,\n",
        "                arrowprops=dict(arrowstyle=\"->\",\n",
        "                                connectionstyle=\"arc3\"))\n",
        "    z -= 0.03\n",
        "ax.set_xlabel('Similarity')\n",
        "ax.set_ylabel('Pairing Probability')\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.yaxis.set_ticks_position('none')\n",
        "ax.yaxis.tick_left()\n",
        "ax.xaxis.set_ticks_position('none')\n",
        "ax.xaxis.tick_bottom()\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## S-Curves: OR-AND Construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "params = zip(rows,bands,colors)\n",
        "ax = plt.gca()\n",
        "plt.title(\"OR-AND S-curves: 60 signatures\")\n",
        "z = 0.2\n",
        "for r,b,c in params:\n",
        "    plt.plot(s, (1-(1-s)**r)**b, label='%d rows'%(r,),\n",
        "             color=c)\n",
        "    t = or_and_threshold(r,b)\n",
        "    pair_prob = (1-(1-t)**r)**b\n",
        "    plt.plot([t,t],[0,pair_prob],'o--',color=c)\n",
        "    ax.annotate('%3.2f'%t, xy=(t,pair_prob),\n",
        "                xytext=(t+0.1,pair_prob+z),color=c,\n",
        "                arrowprops=dict(arrowstyle=\"->\",\n",
        "                                connectionstyle=\"arc3\"))\n",
        "    z -= 0.03\n",
        "ax.set_xlabel('Similarity')\n",
        "ax.set_ylabel('Pairing Probability')\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.yaxis.set_ticks_position('none')\n",
        "ax.yaxis.tick_left()\n",
        "ax.xaxis.set_ticks_position('none')\n",
        "ax.xaxis.tick_bottom()\n",
        "plt.legend(loc='best')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## False Positives and Negatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.figure()\n",
        "plt.title(\"False positives vs. False negatives\")\n",
        "plt.xlabel('Similarity')\n",
        "plt.ylabel('Pairing Probability')\n",
        "r = 4\n",
        "b = 15\n",
        "plt.plot(s, 1-(1-s**r)**b, label='%d rows, %d bands'%(r,b))\n",
        "t = and_or_threshold(r,b)\n",
        "pair_prob = 1-(1-t**r)**b\n",
        "plt.axvline(t,0,1)\n",
        "s1 = np.arange(t,1.0,0.01)\n",
        "y1 = 1-(1-s1**r)**b\n",
        "plt.fill_between(s1, 1.0, y1, facecolor='green')\n",
        "plt.annotate('False negative', xy=(t,0.9), xytext=(t-0.25,0.8),\n",
        "             color='green',\n",
        "            arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"arc3\"))\n",
        "\n",
        "s2 = np.arange(0.0,t,0.01)\n",
        "y2 = 1-(1-s2**r)**b\n",
        "plt.fill_between(s2, 0.0, y2, facecolor='red')\n",
        "plt.annotate('False positive', xy=(t,0.3), xytext=(t+0.2,0.3),\n",
        "             color='red',\n",
        "            arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"arc3\"))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def and_or_curve(s, b, r):\n",
        "    # AND first (s^r), then OR\n",
        "    return 1 - (1 - s**r)**b\n",
        "\n",
        "def or_and_curve(s, b, r):\n",
        "    # OR first (1 - (1-s)^b), then AND\n",
        "    # Note: b is now the \"width\" of the OR, r is the \"count\" of ANDs\n",
        "    return (1 - (1 - s)**b)**r\n",
        "\n",
        "\n",
        "s = np.linspace(0, 1, 100)\n",
        "b, r = 5, 5  # Using symmetric parameters for fair comparison\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(s, and_or_curve(s, b, r), label=f'AND-OR (b={b}, r={r})', linewidth=3, color='blue')\n",
        "plt.plot(s, or_and_curve(s, b, r), label=f'OR-AND (b={b}, r={r})', linewidth=3, color='red', linestyle='--')\n",
        "\n",
        "plt.title(\"Comparison of Cascading Constructions\", fontsize=16)\n",
        "plt.xlabel(\"Jaccard Similarity ($s$)\", fontsize=14)\n",
        "plt.ylabel(\"Probability of Candidate\", fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axvline(0.5, color='gray', linestyle=':', alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Minhashing with Multiple Signatures & Amplification!\n",
        "\n",
        "Consider Jaccard similarity for now:\n",
        "\n",
        "- Generate 20 different signatures for the documents: signatures matrix has signatures as rows and documents as columns\n",
        "\n",
        "- Arrange signatures in 5 **bands**, with each band containing 4 **rows**.\n",
        "\n",
        "- **Candidate Pair:** Any pair of documents whose signatures agree in **every**\n",
        "    row in **some** band.\n",
        "\n",
        "## Find Candidate Pairs\n",
        "\n",
        "1. Hash documents to *buckets* such that similar documents are likely to\n",
        "hash to the same bucket!\n",
        "\n",
        "2. **Actually compare features** of candidate pairs\n",
        "\n",
        "Benefits: Instead of $O(n^2)$ comparisons, we only need $O(n)$ comparisons to\n",
        "find *approximately* similar documents!\n",
        "\n",
        "## General Approach\n",
        "\n",
        "- Choose distance measure for items\n",
        "\n",
        "- Create a matrix of signatures using an **appropriate LSH family**\n",
        "\n",
        "- Construct candidate pairs applying the LSH banding technique\n",
        "\n",
        "- Choose a threshold fraction $t$ for *similarity* of items in order\n",
        "  for them to be regarded as a *true pair*.\n",
        "\n",
        "- Check if the signatures for the candidate pairs match in at least a fraction $t$, or if pairs are sufficiently similar, do a more fine-grained check.\n",
        "\n",
        "## Cosine Distance\n",
        "\n",
        "Distances equals angle (between 0 and $\\pi$) between points in Euclidean space\n",
        "\n",
        "- Can be computed with dot products of the vectors representing the points\n",
        "\n",
        "- Distance is a metric\n",
        "\n",
        "> Note: `scipy` treats the cosine distance as the **cosine** of the angle between points. Hence `scipy` cosine \"distance' is not a distance metric! However, it is convenient because no `acos` (inverse cosine) computations are needed.\n",
        "\n",
        "## LSH Family for Cosine Distance\n",
        "\n",
        "- Data is a collection of $n$-dimensional points (treated as vectors)\n",
        "\n",
        "- A \"hash function\" in the family corresponds to a **random vector**; the hash function applied to a point is the **sign of the dot product** of the point with the random vector.\n",
        "\n",
        "> This yields a $(d_1, d_2, (1-\\frac{d_1}{\\pi}), (1-\\frac{d_2}{\\pi}))$-sensitive hash family for any distances $d_1 < d_2$.\n",
        "\n",
        "**Sketch:** A vector with coordinates $\\pm 1$.\n",
        "\n",
        "Sketches are reasonable approximations to the full LSH family but are only plentiful in very high dimensions!\n",
        "\n",
        "\n",
        "## Hamming Distance\n",
        "\n",
        "Distance between 0/1-valued (binary) vectors of length $n$\n",
        "\n",
        "- equals the number of bit positions that differ, or can also be defined as the *fraction* of bit positions that differ; i.e., it is integer-valued between 0 and $n$ (when un-normalized) or $\\leq 1$ (when normalized by $n$).\n",
        "\n",
        "- it is a metric distance\n",
        "\n",
        "## LSH Family for Hamming Distance\n",
        "\n",
        "- Data is a collection of $n$ dimensional **binary** vectors with positions indexed from 0 through $(n-1)$ from right to left.\n",
        "\n",
        "- A \"hash function\" in the family corresponds to a *projection*: the projection $h_i$ for $0 \\leq i \\leq n-1$ extracts the $i^{th}$ (least significant) bit of a vector.\n",
        "\n",
        "If Hamming distance is *normalized*, this yields a $(d_1, d_2, (1-d_1), (1-d_2))$-sensitive family. Otherwise, it yields a $(d_1, d_2, (1- \\frac{d_1}{n}), (1-\\frac{d_2}{n})$-sensitive family.\n",
        "\n",
        "> Unless the vectors are high-dimensional, this family suffers from a paucity of enough functions to amplify the probabilities!\n",
        "\n",
        "## Euclidean Distances\n",
        "\n",
        "* $L_1$ distance (also called **Manhattan distance**: *sum* of the absolute value difference in each of the dimensions:\n",
        "\n",
        "$L_1(p,q) = \\sum_{i=0}^{n} |p_i - q_i|$\n",
        "\n",
        "* $L_2$ distance is the usual square root of the sum of squares of differences along each dimension:\n",
        "\n",
        "$L_2(p, q) = \\sqrt[2]{\\sum_{i=0}^{n-1} |p_i - q_i|^2}$\n",
        "\n",
        "* $L_k$ distance generalizes $L_2$:\n",
        "\n",
        "$L_k(p, q) = \\sqrt[k]{\\sum_{i=0}^{n-1} |p_i - q_i|^k}$\n",
        "\n",
        "* $L_{\\infty}$ distance is the maximum absolute value of difference along any one dimension:\n",
        "\n",
        "$(p, q) = max_{i} |p_i - q_i|$\n",
        "\n",
        "## LSH family for Euclidean $L_2$ distance\n",
        "\n",
        "- Data is a collection of $2$-dimensional points\n",
        "\n",
        "- A \"hash function\" in the family corresponds to a **random line** that is divided into numbered segments (**buckets**) of length $a$\n",
        "\n",
        "- The hash application is the bucket number reached when a **perpendicular** is dropped from the point onto the line!\n",
        "\n",
        "> This yields a $(\\frac{a}{2}, 2a, \\frac{1}{2}, \\frac{1}{3})$-sensitive hash family."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/shende/Library/CloudStorage/OneDrive-RutgersUniversity/Documents/cs562/s26_562/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}